#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∏–∑ HuggingFace –≤ –ª–æ–∫–∞–ª—å–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
"""
import os
import sys
import argparse
import hashlib
import json
from pathlib import Path
from typing import List, Dict, Any, Optional

try:
    from huggingface_hub import snapshot_download, hf_hub_download
    from transformers import AutoTokenizer, AutoModel
    import torch
except ImportError:
    print("‚ùå –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:")
    print("pip install huggingface_hub transformers torch")
    sys.exit(1)

def calculate_checksum(file_path: Path) -> str:
    """–í—ã—á–∏—Å–ª—è–µ—Ç SHA256 checksum —Ñ–∞–π–ª–∞"""
    sha256_hash = hashlib.sha256()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            sha256_hash.update(chunk)
    return f"sha256:{sha256_hash.hexdigest()}"

def download_model(
    model_id: str, 
    output_dir: Path, 
    revision: Optional[str] = None,
    include_patterns: Optional[List[str]] = None,
    exclude_patterns: Optional[List[str]] = None
) -> Dict[str, Any]:
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ HuggingFace"""
    
    print(f"üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_id}")
    if revision:
        print(f"   –†–µ–≤–∏–∑–∏—è: {revision}")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –º–æ–¥–µ–ª–∏
    model_dir = output_dir / model_id.replace("/", "--")
    model_dir.mkdir(parents=True, exist_ok=True)
    
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
        downloaded_path = snapshot_download(
            repo_id=model_id,
            revision=revision,
            local_dir=str(model_dir),
            include_patterns=include_patterns,
            exclude_patterns=exclude_patterns,
            local_dir_use_symlinks=False  # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã, –∞ –Ω–µ —Å–æ–∑–¥–∞–µ–º —Å–∏–º–ª–∏–Ω–∫–∏
        )
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–∫–∞—á–∞–Ω–∞ –≤: {model_dir}")
        
        # –í—ã—á–∏—Å–ª—è–µ–º checksums –¥–ª—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
        checksums = {}
        for file_path in model_dir.rglob("*"):
            if file_path.is_file():
                relative_path = file_path.relative_to(model_dir)
                checksum = calculate_checksum(file_path)
                checksums[str(relative_path)] = checksum
                print(f"   üìÑ {relative_path}: {checksum[:16]}...")
        
        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
        metadata = {
            "model_id": model_id,
            "revision": revision or "main",
            "downloaded_at": str(Path().cwd()),
            "files": checksums,
            "total_files": len(checksums),
            "total_size_mb": sum(f.stat().st_size for f in model_dir.rglob("*") if f.is_file()) / (1024 * 1024)
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata_file = model_dir / "metadata.json"
        with open(metadata_file, "w", encoding="utf-8") as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print(f"üìä –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: {metadata['total_size_mb']:.1f} MB")
        print(f"üìÑ –§–∞–π–ª–æ–≤: {metadata['total_files']}")
        
        return metadata
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ {model_id}: {e}")
        return {}

def get_model_info(model_id: str, revision: Optional[str] = None) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏"""
    try:
        from huggingface_hub import model_info
        info = model_info(model_id, revision=revision)
        
        return {
            "id": info.id,
            "pipeline_tag": getattr(info, 'pipeline_tag', None),
            "tags": getattr(info, 'tags', []),
            "downloads": getattr(info, 'downloads', 0),
            "likes": getattr(info, 'likes', 0),
            "created_at": getattr(info, 'created_at', None),
            "last_modified": getattr(info, 'last_modified', None),
        }
    except Exception as e:
        print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏: {e}")
        return {}

def test_model(model_id: str, model_dir: Path) -> bool:
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    try:
        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_id}")
        
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä
        tokenizer = AutoTokenizer.from_pretrained(str(model_dir))
        print(f"   ‚úÖ –¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω")
        
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
        model = AutoModel.from_pretrained(str(model_dir))
        print(f"   ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç
        test_text = "Hello, world!"
        inputs = tokenizer(test_text, return_tensors="pt")
        
        with torch.no_grad():
            outputs = model(**inputs)
        
        print(f"   ‚úÖ –¢–µ—Å—Ç –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ")
        print(f"   üìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—ã—Ö–æ–¥–∞: {outputs.last_hidden_state.shape}")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description="–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏–∑ HuggingFace")
    parser.add_argument("models", nargs="+", help="ID –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è")
    parser.add_argument("--output-dir", "-o", default="models", help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: models)")
    parser.add_argument("--revision", "-r", help="–†–µ–≤–∏–∑–∏—è –º–æ–¥–µ–ª–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: main)")
    parser.add_argument("--include", nargs="+", help="–í–∫–ª—é—á–∏—Ç—å —Ç–æ–ª—å–∫–æ —ç—Ç–∏ —Ñ–∞–π–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä: *.safetensors)")
    parser.add_argument("--exclude", nargs="+", help="–ò—Å–∫–ª—é—á–∏—Ç—å —ç—Ç–∏ —Ñ–∞–π–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä: *.bin)")
    parser.add_argument("--test", action="store_true", help="–¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–∫–∞—á–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏")
    parser.add_argument("--info", action="store_true", help="–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª—è—Ö")
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –º–æ–¥–µ–ª–µ–π
    output_dir = Path(args.output_dir)
    output_dir.mkdir(exist_ok=True)
    
    print(f"üöÄ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –≤: {output_dir.absolute()}")
    print("=" * 60)
    
    results = []
    
    for model_id in args.models:
        print(f"\nüì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–¥–µ–ª–∏: {model_id}")
        print("-" * 40)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
        if args.info:
            info = get_model_info(model_id, args.revision)
            if info:
                print(f"   üìã ID: {info.get('id', 'N/A')}")
                print(f"   üè∑Ô∏è  Pipeline: {info.get('pipeline_tag', 'N/A')}")
                print(f"   üì• Downloads: {info.get('downloads', 'N/A')}")
                print(f"   ‚ù§Ô∏è  Likes: {info.get('likes', 'N/A')}")
        
        # –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
        metadata = download_model(
            model_id=model_id,
            output_dir=output_dir,
            revision=args.revision,
            include_patterns=args.include,
            exclude_patterns=args.exclude
        )
        
        if metadata:
            results.append(metadata)
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
            if args.test:
                model_dir = output_dir / model_id.replace("/", "--")
                test_model(model_id, model_dir)
        else:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å: {model_id}")
    
    # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
    if results:
        print(f"\nüìä –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç")
        print("=" * 60)
        
        total_size = sum(r.get('total_size_mb', 0) for r in results)
        total_files = sum(r.get('total_files', 0) for r in results)
        
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(results)}")
        print(f"üìÑ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤: {total_files}")
        print(f"üíæ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {total_size:.1f} MB")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
        report_file = output_dir / "download_report.json"
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump({
                "downloaded_at": str(Path().cwd()),
                "total_models": len(results),
                "total_files": total_files,
                "total_size_mb": total_size,
                "models": results
            }, f, indent=2, ensure_ascii=False)
        
        print(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {report_file}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        print(f"\nüìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π:")
        for model_dir in output_dir.iterdir():
            if model_dir.is_dir():
                print(f"   üìÇ {model_dir.name}")
                for file in sorted(model_dir.iterdir()):
                    if file.is_file():
                        size_mb = file.stat().st_size / (1024 * 1024)
                        print(f"      üìÑ {file.name} ({size_mb:.1f} MB)")
    
    print(f"\nüéâ –ì–æ—Ç–æ–≤–æ!")

if __name__ == "__main__":
    main()
