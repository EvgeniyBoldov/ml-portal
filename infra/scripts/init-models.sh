#!/bin/bash

# –°–∫—Ä–∏–ø—Ç –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ª–µ–≥–∫–∏—Ö ML –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

set -e

echo "üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–µ–≥–∫–∏—Ö ML –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è..."

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
mkdir -p models/embeddings
mkdir -p models/llm

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π
pip install sentence-transformers transformers torch

echo "üì• –°–∫–∞—á–∏–≤–∞–µ–º –ª–µ–≥–∫—É—é –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (all-MiniLM-L6-v2)..."
python -c "
from sentence_transformers import SentenceTransformer
import os
os.makedirs('models/embeddings/all-MiniLM-L6-v2', exist_ok=True)
model = SentenceTransformer('all-MiniLM-L6-v2')
model.save('./models/embeddings/all-MiniLM-L6-v2')
print('‚úÖ –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞')
"

echo "üì• –°–∫–∞—á–∏–≤–∞–µ–º –ª–µ–≥–∫—É—é LLM –º–æ–¥–µ–ª—å (TinyLlama)..."
python -c "
from transformers import AutoModel, AutoTokenizer
import os
os.makedirs('models/llm/tiny-llama', exist_ok=True)
model = AutoModel.from_pretrained('TinyLlama/TinyLlama-1.1B-Chat-v1.0')
tokenizer = AutoTokenizer.from_pretrained('TinyLlama/TinyLlama-1.1B-Chat-v1.0')
model.save_pretrained('./models/llm/tiny-llama')
tokenizer.save_pretrained('./models/llm/tiny-llama')
print('‚úÖ LLM –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞')
"

echo "üìä –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –º–æ–¥–µ–ª–µ–π..."
du -sh models/embeddings/all-MiniLM-L6-v2
du -sh models/llm/tiny-llama

echo "‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞!"
echo "üìÅ –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:"
echo "   - –≠–º–±–µ–¥–¥–∏–Ω–≥–∏: models/embeddings/all-MiniLM-L6-v2"
echo "   - LLM: models/llm/tiny-llama"
